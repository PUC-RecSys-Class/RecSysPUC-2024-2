{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Práctico Graph Neural Network (GraphSAGE)\n",
        "\n",
        "\n",
        "Sistemas Recomendadores <br>\n",
        "**Profesor:** Denis Parra <br>\n",
        "**Ayudantes:** Carlos Muñoz & Pablo Messina & Alejandro Plaza & Daniel Sebastian\n",
        "\n",
        "Agradecimientos: Álvaro Labarca\n",
        "\n",
        "En este práctico se utilizará un [tutorial interactivo de ArangoDB Interactive Tutorials](https://github.com/arangodb/interactive_tutorials/blob/master/notebooks/example_output/Comprehensive_GraphSage_Guide_with_PyTorchGeometric_Output.ipynb) para estudiar el funcionamiento del algoritmo GraphSAGE. GraphSAGE es un modelo de GCN (Graph Convolutional Network) que utiliza una red convolucional sobre datos representados en forma de grafos para generar embeddings que capturen las relaciones complejas entre distintos nodos. En particular, en este práctico se trabajará con el dataset [obgn-products](https://ogb.stanford.edu/docs/nodeprop/#ogbn-products), el cual utiliza un grafo homogéneo no direccionado para representar una cadena de co-compras de productos de Amazon, la cual será utilizada para generar embeddings de los productos que contiene."
      ],
      "metadata": {
        "id": "OCeyBTw9D-f6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdSU337b5T22"
      },
      "source": [
        "## Important Note!!\n",
        "If you are running this notebook on Google Colab, please make sure to enable hardware acceleration using either a GPU or a TPU. If it is run with CPU-only enabled, generating the word embeddings will take an incredibly long time! Hardware acceleration can be enabled by navigating to `Runtime` -> `Change Runtime`. This will present you with a popup, where you can select an appropriate `Hardware Accelerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbQXth1kDRbs"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "inicio = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD6AdwYN75zS"
      },
      "source": [
        "# Installing Pytorch Geometric\n",
        "%%capture\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-cluster -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install ogb\n",
        "!pip install umap-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-JrMVQK9KJz"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.data import NeighborSampler\n",
        "from torch_geometric.nn import SAGEConv\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "from pandas.core.common import flatten\n",
        "# importing obg datatset\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "from pandas.core.common import flatten\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(rc={'figure.figsize':(16.7,8.27)})\n",
        "sns.set_theme(style=\"ticks\")\n",
        "import collections\n",
        "from scipy.special import softmax\n",
        "import umap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7tiIPoO9DCR"
      },
      "source": [
        "# download and loading the obg dataset\n",
        "root = osp.join(osp.dirname(osp.realpath('./')), 'data', 'products')\n",
        "dataset = PygNodePropPredDataset('ogbn-products', root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj1BvL4JEpM5"
      },
      "source": [
        "# split_idx contains a dictionary of train, validation and test node indices\n",
        "split_idx = dataset.get_idx_split()\n",
        "# predefined ogb evaluator method used for validation of predictions\n",
        "evaluator = Evaluator(name='ogbn-products')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY4ma_tGEqUR"
      },
      "source": [
        "Lets check the training, validation and test node split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQS3Li4GEu5K"
      },
      "source": [
        "# lets check the node ids distribution of train, test and val\n",
        "print('Number of training nodes:', split_idx['train'].size(0))\n",
        "print('Number of validation nodes:', split_idx['valid'].size(0))\n",
        "print('Number of test nodes:', split_idx['test'].size(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf8ZUtcdlMr1"
      },
      "source": [
        "# loading the dataset\n",
        "data = dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pslfd5LIE0CO"
      },
      "source": [
        "Graph Statistics of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75KFA7Rlcv2Y"
      },
      "source": [
        "# lets check some graph statistics of ogb-product graph\n",
        "print(\"Number of nodes in the graph:\", data.num_nodes)\n",
        "print(\"Number of edges in the graph:\", data.num_edges)\n",
        "print(\"Node feature matrix with shape:\", data.x.shape) # [num_nodes, num_node_features]\n",
        "print(\"Graph connectivity in COO format with shape:\", data.edge_index.shape) # [2, num_edges]\n",
        "print(\"Target to train against :\", data.y.shape)\n",
        "print(\"Node feature length\", dataset.num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I24vcbfkl4B"
      },
      "source": [
        "# checking the number of unique labels\n",
        "# there are 47 unique categories of product\n",
        "data.y.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYCpEJHonXFk"
      },
      "source": [
        "# load integer to real product category from label mapping provided inside the dataset\n",
        "df = pd.read_csv('/data/products/ogbn_products/mapping/labelidx2productcategory.csv.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y92KPN10rPUi"
      },
      "source": [
        "# lets see some of the product categories\n",
        "df[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICJ9yuk2r8pY"
      },
      "source": [
        "# creating a dictionary of product category and corresponding integer label\n",
        "label_idx, prod_cat = df.iloc[: ,0].values, df.iloc[: ,1].values\n",
        "label_mapping = dict(zip(label_idx, prod_cat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qlO7Jfnr8co"
      },
      "source": [
        "# counting the numbers of samples for each category\n",
        "y = data.y.tolist()\n",
        "y = list(flatten(y))\n",
        "count_y = collections.Counter(y)\n",
        "print(count_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lp8bCAOztke"
      },
      "source": [
        "## Neighborhood Sampling\n",
        "\n",
        "This module iteratively samples neighbors (at each layer) and constructs bipartite graphs that simulate the actual computation flow of GNNs.\n",
        "\n",
        "sizes: denotes how much neighbors we want to sample for each node in each layer.\n",
        "\n",
        "`NeighborSampler` holds the current\n",
        "    :obj:`batch_size`, the IDs :obj:`n_id` of all nodes involved in the\n",
        "    computation, and a list of bipartite graph objects via the tuple\n",
        "    :obj:`(edge_index, e_id, size)`, where :obj:`edge_index` represents the\n",
        "    bipartite edges between source and target nodes, :obj:`e_id` denotes the\n",
        "    IDs of original edges in the full graph, and :obj:`size` holds the shape\n",
        "    of the bipartite graph.\n",
        "\n",
        "The actual computation graphs are then returned in reverse-mode, meaning\n",
        "    that we pass messages from a larger set of nodes to a smaller one, until we\n",
        "    reach the nodes for which we originally wanted to compute embeddings.\n",
        "\n",
        "To refer in detail: https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/data/sampler.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mf25FS-zsuE"
      },
      "source": [
        "train_idx = split_idx['train']\n",
        "train_loader = NeighborSampler(data.edge_index, node_idx=train_idx,\n",
        "                               sizes=[15, 10, 5], batch_size=1024,\n",
        "                               shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader.edge_index)\n",
        "print(train_idx)"
      ],
      "metadata": {
        "id": "IdB2rJIHXr2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXHyalAW6tZx"
      },
      "source": [
        "# GraphSage Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzy64TKsLAXA"
      },
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        # `train_loader` computes the k-hop neighborhood of a batch of nodes,\n",
        "        # and returns, for each layer, a bipartite graph object, holding the\n",
        "        # bipartite edges `edge_index`, the index `e_id` of the original edges,\n",
        "        # and the size/shape `size` of the bipartite graph.\n",
        "        # Target nodes are also included in the source nodes so that one can\n",
        "        # easily apply skip-connections or add self-loops.\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            xs = []\n",
        "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "            xs.append(x)\n",
        "            if i == 0:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "        #return x.log_softmax(dim=-1)\n",
        "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "\n",
        "        # Compute representations of nodes layer by layer, using *all*\n",
        "        # available edges. This leads to faster computation in contrast to\n",
        "        # immediately computing the final representations of each batch.\n",
        "        total_edges = 0\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in subgraph_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                total_edges += edge_index.size(1)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = F.relu(x)\n",
        "                xs.append(x)\n",
        "\n",
        "                pbar.update(batch_size)\n",
        "\n",
        "            if i == 0:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEOFb1yj7C__"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SAGE(dataset.num_features, 256, dataset.num_classes, num_layers=3)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJt_AqXG7IjN"
      },
      "source": [
        "# loading node feature matrix and node labels\n",
        "x = data.x.to(device)\n",
        "y = data.y.squeeze().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUIzCzSX7KzW"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "\n",
        "    #pbar = tqdm(total=train_idx.size(0))\n",
        "    #pbar.set_description(f'Epoch {epoch:02d}')\n",
        "\n",
        "    total_loss = total_correct = 0\n",
        "    for batch_size, n_id, adjs in train_loader:\n",
        "        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
        "        adjs = [adj.to(device) for adj in adjs]\n",
        "        optimizer.zero_grad()\n",
        "        l1_emb, l2_emb, l3_emb = model(x[n_id], adjs)\n",
        "        #print(\"Layer 1 embeddings\", l1_emb.shape)\n",
        "        #print(\"Layer 2 embeddings\", l1_emb.shape)\n",
        "        out = l3_emb.log_softmax(dim=-1)\n",
        "        loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())\n",
        "        #pbar.update(batch_size)\n",
        "\n",
        "    #pbar.close()\n",
        "\n",
        "    loss = total_loss / len(train_loader)\n",
        "    approx_acc = total_correct / train_idx.size(0)\n",
        "\n",
        "    return loss, approx_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KI_FuNGQv00"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    loss, acc = train(epoch)\n",
        "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1An8iW1xvg2"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHuEVx8AEOMx"
      },
      "source": [
        "#compute the number of trainable parameters:\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_parameter = count_parameters(model)\n",
        "print(total_parameter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJFDgZgtEp-A"
      },
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK5yhidAIUBK"
      },
      "source": [
        "## Saving the model for inference part\n",
        "\n",
        "We need to save the model for the infernce part because google colab cannot create two graph loaders at the same time because of the limitation of the RAM size. Therefore, we first train with train_loader and then make inferences on test data using this saved model.\n",
        "\n",
        "Here you can either save the model on google MyDrive or locally on your computer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5nCBbSGGPVy"
      },
      "source": [
        "#torch.save(model, '/content/drive/MyDrive/model_weights/graph_embeddings/model.pt')\n",
        "\n",
        "# saving model in mydrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "fp = '/content/drive/MyDrive/model.pt'\n",
        "\n",
        "torch.save(model, './model.pt')\n",
        "torch.save(model, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j--snNq4Id04"
      },
      "source": [
        "# Inference: Let's check GraphSage Inductive Power!!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukruthZaJbO6"
      },
      "source": [
        "This part includes making the use of trained GraphSage model in order to compute node embeddings and performing node category prediction on test data.\n",
        "Aftwerwards, we compare the <b>U-Map visualizations of node embeddings</b> at 3 different layers of GraphSage and draw some interesting observations.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uMqkojRLCkM"
      },
      "source": [
        "## Headsup : At this point of time you need to restart the colab runtime!!!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Pytorch Geometric\n",
        "%%capture\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-cluster -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install ogb\n",
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "9T3a7SuaomzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W36DhyRwI0lp"
      },
      "source": [
        "## load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKjf-f58xBn2"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.data import NeighborSampler\n",
        "from torch_geometric.nn import SAGEConv\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "from pandas.core.common import flatten\n",
        "# importing obg datatset\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "from pandas.core.common import flatten\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(rc={'figure.figsize':(16.7,8.27)})\n",
        "sns.set_theme(style=\"ticks\")\n",
        "import collections\n",
        "from scipy.special import softmax\n",
        "import umap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ_Soqg0QRrz"
      },
      "source": [
        "# download and loading the obg dataset\n",
        "root = osp.join(osp.dirname(osp.realpath('./')), 'data', 'products')\n",
        "dataset = PygNodePropPredDataset('ogbn-products', root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExNUtb43Qk-K"
      },
      "source": [
        "# split_idx contains a dictionary of train, validation and test node indices\n",
        "split_idx = dataset.get_idx_split()\n",
        "# predefined ogb evaluator method used for validation of predictions\n",
        "evaluator = Evaluator(name='ogbn-products')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnKFTVXHQs6Q"
      },
      "source": [
        "# loading the dataset\n",
        "data = dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JONz-ZZnI6SN"
      },
      "source": [
        "subgraph_loader = NeighborSampler(data.edge_index, node_idx=None, sizes=[-1],\n",
        "                                  batch_size=1024, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl5MitM-Q9qn"
      },
      "source": [
        "# load integer to real product category from label mapping provided inside the dataset\n",
        "df = pd.read_csv('/data/products/ogbn_products/mapping/labelidx2productcategory.csv.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL6weyjMRGFI"
      },
      "source": [
        "# creating a dictionary of product category and corresponding integer label\n",
        "label_idx, prod_cat = df.iloc[: ,0].values, df.iloc[: ,1].values\n",
        "label_mapping = dict(zip(label_idx, prod_cat))\n",
        "print(\"Label mapping\", label_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkCGZzgbRKL_"
      },
      "source": [
        "y = data.y.tolist()\n",
        "y = list(flatten(y))\n",
        "count_y = collections.Counter(y)\n",
        "print(count_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0WYymcXKfIj"
      },
      "source": [
        "## Need to define the model class again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0VZvUx9KXQc"
      },
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adjs):\n",
        "        # `train_loader` computes the k-hop neighborhood of a batch of nodes,\n",
        "        # and returns, for each layer, a bipartite graph object, holding the\n",
        "        # bipartite edges `edge_index`, the index `e_id` of the original edges,\n",
        "        # and the size/shape `size` of the bipartite graph.\n",
        "        # Target nodes are also included in the source nodes so that one can\n",
        "        # easily apply skip-connections or add self-loops.\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            xs = []\n",
        "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
        "            x = self.convs[i]((x, x_target), edge_index)\n",
        "            if i != self.num_layers - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=0.5, training=self.training)\n",
        "            xs.append(x)\n",
        "            if i == 0:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "        #return x.log_softmax(dim=-1)\n",
        "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings\n",
        "\n",
        "    def inference(self, x_all):\n",
        "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
        "        pbar.set_description('Evaluating')\n",
        "\n",
        "        # Compute representations of nodes layer by layer, using *all*\n",
        "        # available edges. This leads to faster computation in contrast to\n",
        "        # immediately computing the final representations of each batch.\n",
        "        total_edges = 0\n",
        "        for i in range(self.num_layers):\n",
        "            xs = []\n",
        "            for batch_size, n_id, adj in subgraph_loader:\n",
        "                edge_index, _, size = adj.to(device)\n",
        "                total_edges += edge_index.size(1)\n",
        "                x = x_all[n_id].to(device)\n",
        "                x_target = x[:size[1]]\n",
        "                x = self.convs[i]((x, x_target), edge_index)\n",
        "                if i != self.num_layers - 1:\n",
        "                    x = F.relu(x)\n",
        "                xs.append(x)\n",
        "\n",
        "                pbar.update(batch_size)\n",
        "\n",
        "            if i == 0:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_1_embeddings = x_all\n",
        "            elif i == 1:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_2_embeddings = x_all\n",
        "            elif i == 2:\n",
        "                x_all = torch.cat(xs, dim=0)\n",
        "                layer_3_embeddings = x_all\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9c7Ga0LHBZS"
      },
      "source": [
        "# loading the saved model\n",
        "# Load model from Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "fp = '/content/drive/My Drive/model.pt'\n",
        "model = torch.load(fp)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INSoJNkSHqud"
      },
      "source": [
        "# load node feature matrix and labels\n",
        "x = data.x.to(device)\n",
        "y = data.y.squeeze().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQT8wHCaWC1R"
      },
      "source": [
        "Perform evaluation on test data with saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSnrbmf-H8yu"
      },
      "source": [
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "\n",
        "    l1_embeddings, l2_embeddings, l3_embeddings = model.inference(x)\n",
        "    out = l3_embeddings\n",
        "    y_true = y.cpu().unsqueeze(-1)\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return test_acc, l1_embeddings, l2_embeddings, l3_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9LHxXl5Lu8D"
      },
      "source": [
        "# shapes\n",
        "test_acc, l1_embeddings, l2_embeddings, l3_embeddings = test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYNtQqWBLx0z"
      },
      "source": [
        "print('Final Test acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V15qrFXyR34G"
      },
      "source": [
        "## Embeddings of whole datastet layer-wise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOz2R9K1MPER"
      },
      "source": [
        "print(\"Layer 1 Embeddings Shape:\",l1_embeddings.shape)\n",
        "print(\"Layer 2 Embeddings Shape:\",l2_embeddings.shape)\n",
        "print(\"Layer 3 Embeddings Shape:\",l3_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcDHiEvSAEU"
      },
      "source": [
        "## Embeddings of Test data layer-wise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete x and y variables with the original data entries in order to make room for the RAM in Colab."
      ],
      "metadata": {
        "id": "cRm3A3W6CU28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del x\n",
        "del y"
      ],
      "metadata": {
        "id": "droccOtTChlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7a6mTYRNM7t"
      },
      "source": [
        "l1_embedding_test = l1_embeddings[split_idx['test']]\n",
        "l2_embedding_test = l2_embeddings[split_idx['test']]\n",
        "l3_embedding_test = l3_embeddings[split_idx['test']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c35fPAzNT2G"
      },
      "source": [
        "l1_embedding_test.shape, l2_embedding_test.shape, l3_embedding_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwT-L2-7NZuG"
      },
      "source": [
        "l3_embedding_smax_test = softmax(l3_embedding_test.detach().cpu().numpy(), axis=1)\n",
        "l3_embedding_smax_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLBje4ZrPRDO"
      },
      "source": [
        "# saving predictions from last layer embeddings\n",
        "y_pred = np.argmax(l3_embedding_smax_test, axis=1)\n",
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjUy_SNkPcOQ"
      },
      "source": [
        "## Embedding Visualizations with Umap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY2yEqFvPbYX"
      },
      "source": [
        "reducer = umap.UMAP()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOmcz9zTSOoF"
      },
      "source": [
        "## Layer-1 Node Embeddings Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2LDzm8yMlSB"
      },
      "source": [
        "# sample test data\n",
        "l1_emb_sample = l1_embedding_test[:2000].detach().cpu().numpy()\n",
        "y_pred_sample = y_pred[:2000]\n",
        "l1_emb_sample.shape, y_pred_sample.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G15s2jUgSWpX"
      },
      "source": [
        "y_pred_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd0HghH_Sov5"
      },
      "source": [
        "# label mapping\n",
        "y_pred_sample_products = []\n",
        "for y in y_pred_sample:\n",
        "    y_pred_sample_products.append(label_mapping[y])\n",
        "\n",
        "y_pred_sample_products = np.array(y_pred_sample_products )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABWa3KHcSrf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5af159-0474-42e2-c082-6f2c5d90bd10"
      },
      "source": [
        "# number of unique classes present in sampled data\n",
        "len(set(y_pred_sample_products.tolist()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVHZADMNS952"
      },
      "source": [
        "color_coding = ['green','yellowgreen','brown','dodgerblue','red','black', 'grey',\n",
        "                'darkgreen', 'cyan', 'yellow', 'magenta', 'lightcoral', 'rosybrown', 'maroon',\n",
        "                'peru', 'khaki', 'olive', 'darkseagreen', 'lightseagreen', 'lightskyblue', 'darkviolet',\n",
        "                'pink', 'deeppink', 'thistle', 'ivory', 'gold', 'lavender']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE7nE2hVSvhd"
      },
      "source": [
        "Now we need to train our reducer, letting it learn about the manifold. For this UMAP follows the sklearn API and has a method fit which we pass the data we want the model to learn from.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srROLxnWSuIV"
      },
      "source": [
        "l1_reduced_emb = reducer.fit_transform(l1_emb_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbqyYlCTSzI6"
      },
      "source": [
        "# reduced representation\n",
        "l1_reduced_emb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYuTBpBrS3h3"
      },
      "source": [
        "y_pred_sample_products.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI9u7ZeSS5UG"
      },
      "source": [
        "# plot\n",
        "sns.scatterplot(x = l1_reduced_emb[:, 0], y = l1_reduced_emb[:, 1], hue = y_pred_sample_products, palette=color_coding)\n",
        "# Put the legend out of the figure\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Comente la capacidad de la primera capa del modelo para representar las clases, ¿Qué clases representa bien?, ¿Cuáles no representa bien? y ¿Por qué cree usted?"
      ],
      "metadata": {
        "id": "rRb6w8C9bsRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Respuesta"
      ],
      "metadata": {
        "id": "OWAoQRtScVvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPWzpK8iTmUA"
      },
      "source": [
        "## Layer-2 Node Embeddings Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWkjbYWxT0F1"
      },
      "source": [
        "# sample test data\n",
        "l2_emb_sample = l2_embedding_test[:2000].detach().cpu().numpy()\n",
        "y_pred_sample = y_pred[:2000]\n",
        "l2_emb_sample.shape, y_pred_sample.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRFoYl20THXg"
      },
      "source": [
        "l2_reduced_emb = reducer.fit_transform(l2_emb_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92aIZftTTsg4"
      },
      "source": [
        "# plot\n",
        "sns.scatterplot(x = l2_reduced_emb[:, 0], y = l2_reduced_emb[:, 1], hue = y_pred_sample_products,  palette=color_coding)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Comente la capacidad de la segunda capa del modelo para representar las clases, ¿Qué clases representa bien?, ¿Cuáles no representa bien? y ¿Por qué cree usted?. Comente los resultados en relación a la capa anterior."
      ],
      "metadata": {
        "id": "O-qolRHpcmqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Respuesta"
      ],
      "metadata": {
        "id": "2EiUsYIhcmqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMV90GaQU04t"
      },
      "source": [
        "## Layer-3 Node Embeddings Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vifrSBr-U6eG"
      },
      "source": [
        "# sample test data\n",
        "l3_emb_sample = l3_embedding_test[:2000].detach().cpu().numpy()\n",
        "y_pred_sample = y_pred[:2000]\n",
        "l3_emb_sample.shape, y_pred_sample.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9CkYtIIVGQv"
      },
      "source": [
        "l3_reduced_emb = reducer.fit_transform(l3_emb_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rBcI8TlVAks"
      },
      "source": [
        "# plot\n",
        "sns.scatterplot(x = l3_reduced_emb[:, 0], y = l3_reduced_emb[:, 1], hue = y_pred_sample_products, palette=color_coding)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Comente la capacidad de la tercera capa del modelo para representar las clases, ¿Qué clases representa bien?, ¿Cuáles no representa bien? y ¿Por qué cree usted?. Comente los resultados en relación a las capas anteriores."
      ],
      "metadata": {
        "id": "JmyKqji1c9zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Respuesta"
      ],
      "metadata": {
        "id": "gEhn8N9Qc9zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Comente dos casos de uso que pueden verse beneficiados al usar las representaciones anteriores."
      ],
      "metadata": {
        "id": "uuunvXbRdL9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Respuesta"
      ],
      "metadata": {
        "id": "KFSQkQF5dL9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AvYRIezcDfS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(f\"Tiempo de ejecución: {execution_time} segundos\")"
      ],
      "metadata": {
        "id": "7Q_fmC5nDfVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e54ac99-d39a-4a81-fc7e-b4fc6c4cc9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución: 14034.83057641983 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93DUw6GzDfeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRXsLY7ODfhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JtACH_XDfkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxyBpS6bDfnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7ya9lX3DfqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFq79FqyDfst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}